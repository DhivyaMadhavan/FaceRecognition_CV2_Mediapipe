{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwVdmXUqQ7qJ05rC35pNNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhivyaMadhavan/FaceRecognition_CV2_Mediapipe/blob/main/Proctoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhbLIzeZaBOY",
        "outputId": "bad4adbc-3251-4e3f-922e-a22309dbca2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.4 sounddevice-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#capture screenshots initially\n",
        "\n"
      ],
      "metadata": {
        "id": "zjrC2ABzgVMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code captures 3 initial face images from the video"
      ],
      "metadata": {
        "id": "NDygPZidN2x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "def get_face_features(frame, face_landmarks):\n",
        "    ih, iw, _ = frame.shape\n",
        "    landmarks = np.array([\n",
        "        [landmark.x * iw, landmark.y * ih] for landmark in face_landmarks.landmark\n",
        "    ])\n",
        "    return landmarks.flatten()  # Flatten to a 1D vector\n",
        "\n",
        "def capture_initial_faces(video_path, num_samples=3):\n",
        "    screenshots = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
        "        max_num_faces=10,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    sample_count = 0\n",
        "\n",
        "    while cap.isOpened() and sample_count < num_samples:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = mp_face_mesh.process(rgb_frame)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                screenshots.append(frame)\n",
        "                sample_count += 1\n",
        "                if sample_count >= num_samples:\n",
        "                    break\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Save initial screenshots\n",
        "    for i, screenshot in enumerate(screenshots):\n",
        "        cv2.imwrite(f\"initial_face_{i+1}.png\", screenshot)\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/Untitled design (1).mp4'  # Replace with your video file path\n",
        "capture_initial_faces(video_path)\n"
      ],
      "metadata": {
        "id": "c6bkS79zMnbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d48c770-9bcb-4dfe-e780-432815c37830"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#with saved images , frame_skip = 3"
      ],
      "metadata": {
        "id": "ThF8H713gbY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YAJHAjxlgbXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "def get_face_features(frame, face_landmarks):\n",
        "    ih, iw, _ = frame.shape\n",
        "    landmarks = np.array([\n",
        "        [landmark.x * iw, landmark.y * ih] for landmark in face_landmarks.landmark\n",
        "    ])\n",
        "    return landmarks.flatten()  # Flatten to a 1D vector\n",
        "\n",
        "def load_initial_face_features(image_paths):\n",
        "    face_features = []\n",
        "    mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = cv2.imread(image_path)\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = mp_face_mesh.process(rgb_image)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                features = get_face_features(image, face_landmarks)\n",
        "                face_features.append(features)\n",
        "\n",
        "    return face_features\n",
        "\n",
        "def compare_face_features(initial_features, current_features, threshold=5500):\n",
        "    for feature in initial_features:\n",
        "        distance = np.linalg.norm(feature - current_features)\n",
        "        if distance < threshold:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def process_frame(frame, face_mesh, initial_features, head_movement_threshold, last_face_positions, suspicious_activities):\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb_frame)\n",
        "\n",
        "    current_face_boxes = []\n",
        "    detected_features = []\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        num_faces = len(results.multi_face_landmarks)\n",
        "        if num_faces == 0:\n",
        "            suspicious_activities['No Face Detected'] += 1\n",
        "        elif num_faces > 1:\n",
        "            suspicious_activities['Multiple Faces Detected'] += 1\n",
        "\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            ih, iw, _ = frame.shape\n",
        "            x_min = min(int(landmark.x * iw) for landmark in face_landmarks.landmark)\n",
        "            x_max = max(int(landmark.x * iw) for landmark in face_landmarks.landmark)\n",
        "            y_min = min(int(landmark.y * ih) for landmark in face_landmarks.landmark)\n",
        "            y_max = max(int(landmark.y * ih) for landmark in face_landmarks.landmark)\n",
        "            face_box = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
        "            current_face_boxes.append(face_box)\n",
        "\n",
        "            # Extract features for face comparison\n",
        "            features = get_face_features(frame, face_landmarks)\n",
        "            detected_features.append(features)\n",
        "\n",
        "    movement_detected = False\n",
        "    if last_face_positions:\n",
        "        for current_box in current_face_boxes:\n",
        "            x, y, w, h = current_box\n",
        "            for last_box in last_face_positions:\n",
        "                lx, ly, lw, lh = last_box\n",
        "                cx, cy = x + w // 2, y + h // 2\n",
        "                lc_x, lc_y = lx + lw // 2, ly + lh // 2\n",
        "                if np.sqrt((cx - lc_x) ** 2 + (cy - lc_y) ** 2) > head_movement_threshold:\n",
        "                    movement_detected = True\n",
        "                    break\n",
        "            if movement_detected:\n",
        "                break\n",
        "\n",
        "    if movement_detected:\n",
        "        suspicious_activities['Rapid Head Movement'] += 1\n",
        "\n",
        "    # Check if the detected face features match the initial ones\n",
        "    same_person_detected = False\n",
        "    for feature in detected_features:\n",
        "        if compare_face_features(initial_features, feature):\n",
        "            same_person_detected = True\n",
        "            break\n",
        "\n",
        "    if not same_person_detected:\n",
        "        suspicious_activities['isSamePerson'] = False\n",
        "\n",
        "    return current_face_boxes\n",
        "\n",
        "def process_video_for_faces_and_movement(video_path, initial_face_paths, head_movement_threshold=10, frame_skip=3):\n",
        "    initial_face_features = load_initial_face_features(initial_face_paths)\n",
        "    if not initial_face_features:\n",
        "        print(\"No faces detected in the initial screenshots.\")\n",
        "        return\n",
        "\n",
        "    suspicious_activities = {\n",
        "        'Multiple Faces Detected': 0,\n",
        "        'Rapid Head Movement': 0,\n",
        "        'isSamePerson': True\n",
        "    }\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
        "        max_num_faces=10,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    last_face_positions = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % frame_skip != 0:\n",
        "            continue\n",
        "\n",
        "        last_face_positions = process_frame(frame, mp_face_mesh, initial_face_features, head_movement_threshold, last_face_positions, suspicious_activities)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Print the summary of activities\n",
        "    print(\"Activities summary:\")\n",
        "    for activity, count in suspicious_activities.items():\n",
        "        if activity == 'isSamePerson':\n",
        "            print(f\"{activity}: {'True' if count else 'False'}\")\n",
        "        else:\n",
        "            print(f\"{activity}: {count} times\")\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/Untitled design (1).mp4'  # Replace with your video file path\n",
        "initial_face_paths = [\n",
        "    '/content/initial_face_1.png',  # Replace with your initial face screenshot paths\n",
        "    '/content/initial_face_2.png',\n",
        "    '/content/initial_face_3.png'\n",
        "]\n",
        "process_video_for_faces_and_movement(video_path, initial_face_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbekX4cHLjHg",
        "outputId": "50bd164c-0ee7-430e-c8bc-104264fd7df4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activities summary:\n",
            "Multiple Faces Detected: 0 times\n",
            "Rapid Head Movement: 15 times\n",
            "isSamePerson: True\n"
          ]
        }
      ]
    }
  ]
}